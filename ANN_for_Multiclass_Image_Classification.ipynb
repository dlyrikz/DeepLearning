# Step 1: Installation and Setup

# Install Tensorflow
import tensorflow as tf
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt


#print(tf.__version__)

# Step 2: Data Preprocessing

# Importing the dataset
from tensorflow.keras.datasets import fashion_mnist


# Loading the dataset
(x_train, y_train),(x_test, y_test) = fashion_mnist.load_data()


# Check the shape of the datasets
x_train.shape , x_test.shape

y_train.shape , y_test.shape

x_train
np.max(x_train), np.min(x_train), np.mean(x_train) # check x_train max ,min & mean value

y_train
np.max(y_train), np.min(y_train) # check y_train max ,min value

# Assign classes to array

class_names = ['0 Top/T-shirt','1 Trouser', '2 Pullover','3 Dress', '4 Coat','5 Sandal', '6 Shirt', '7 Sneaker', '8 Bag','9 Ankle Boot']
print(class_names)

# Data Exploration
plt.figure()
plt.imshow(x_train[1])
plt.colorbar()

y_train[1]

# Normalize the Dataset -- Tip before training Machine Model NN learns faster
x_train = x_train / 255.0
x_test = x_test / 255.0

# Recheck Data Exploration for Normalization colorbar value should be 0 - 1
plt.figure()
plt.imshow(x_train[1])
plt.colorbar()

# Next Flatten the dataset 2 Dimension array  to single vector

x_train.shape, x_test.shape

x_train = x_train.reshape(-1, 28*28)    #-1 Means select all in the array
x_test = x_test.reshape(-1, 28*28)
x_train.shape, x_test.shape

# Step 3: Building the Model

# Define an object
model = tf.keras.models.Sequential()  # sequence of Layers

# Adding first fully connected hidden layer
# 1) units (Number of neurons) = 128
# 2) activation function = ReLU
# 3) input shape = (784.)

model.add(tf.keras.layers.Dense(units=128, activation='relu', input_shape=(784,)))

# Adding the second layer with dropout --prevents overfitting in the training process

model.add(tf.keras.layers.Dropout(0.3)) # regularization technique, prevents overfitting

# Adding the Output Layer
# 1) units = 10  ** because 10 classes in output
# 2) activation = softmax  ** Multiple output use softmax / Binary output use sigmoid

model.add(tf.keras.layers.Dense(units=10, activation='softmax'))


# Step 4: Training the Model

# Compiling the model
# 1) Optimizer - adam, (minimize the loss function)
# 2) loss function = sparse_categorical_crossentropy (acts as guide to optimizer)
# 3) matrices = sparse_categorical_accuracy  ***Tip for Binary use categorical_accuracy

model.compile(optimizer='adam',loss='sparse_categorical_crossentropy', metrics=['sparse_categorical_accuracy'])

model.summary()

# Training the Model

model.fit(x_train, y_train, epochs=10)     # epochs means the number of times to train the model

# Step 5: Model evaluation and prediction

# model evaluation
test_loss, test_accuracy = model.evaluate(x_test, y_test)


print('Test Accuracy: {}'.format(test_accuracy))

# Model Prediction
y_predict = model.predict_classes(x_test)

print(y_predict)

y_predict[11], y_test[11]  # predicted output and actual output

print(class_names)

# Confusion Metrics
from sklearn.metrics import confusion_matrix, accuracy_score
cm = confusion_matrix(y_test, y_predict)
print(cm)

acc_cm = accuracy_score(y_test, y_predict)
print(acc_cm)
